{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introductory-promotion",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93c6514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import random\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "### steps to build a CBOW model\n",
    "- import and preprocess the text\n",
    "- window the data to create x (context words) and y (center word)\n",
    "- convert the context words and center word into vectors. each vector has the size of vocab length\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067a37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-namibia",
   "metadata": {},
   "source": [
    "### import the data and store it as an array in the variable: corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740d6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('blogtext_5k.csv')\n",
    "corpus = data['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84fe0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'           Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.         '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96dd3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(corpus):\n",
    "    # loop through each document in the corpus\n",
    "    for i in range(len(corpus)):\n",
    "        # remove extra whitespace, lowercase all letters, and convert '\\n' to ' '\n",
    "        string = re.sub('\\n',' ',corpus[i].strip().lower())\n",
    "        # remove all characters which aren't letters or spaces\n",
    "        string = re.sub('[^a-z ]','',string)\n",
    "\n",
    "        # lemmatize all words\n",
    "        string = \" \".join([lemmatizer.lemmatize(word) for word in string.split()])\n",
    "        corpus[i] = string\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddeab473",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27af53b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'info ha been found page and mb of pdf file now i have to wait untill our team leader ha processed it and learns html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-database",
   "metadata": {},
   "source": [
    "### Here, we go through the full corpus taking a window size of 5.\n",
    "### This means that we count the two words before and two words after as context words, and the center word is the word which we need to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7cb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(corpus, w_size):\n",
    "    \n",
    "    # window size has to be odd\n",
    "    assert( w_size % 2 != 0 )\n",
    "\n",
    "    x = [] # context words\n",
    "    y = [] # center word\n",
    "    \n",
    "    for sent in corpus:\n",
    "\n",
    "        sent = sent.split(' ')\n",
    "        i = 0\n",
    "        mid = int(w_size / 2)\n",
    "\n",
    "        while i <= len(sent) - w_size:\n",
    "            target = sent[i+mid]\n",
    "            context = sent[i:i+mid] + sent[i+mid+1:i+w_size]\n",
    "\n",
    "            x += context\n",
    "            y.append(target)\n",
    "            i += 1\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ruled-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = window(corpus, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf6c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(min_df=4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initizalize and fit the vectorizer\n",
    "vec = CountVectorizer(ngram_range=(1, 1), min_df=4)\n",
    "vec.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ce2ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2906472, 726618)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-bleeding",
   "metadata": {},
   "source": [
    "### x is 4 times the length of y because for each center word, we have 4 context words. We will reshape the inputs in the generator function below\n",
    "\n",
    "### a custom generator function is built to reduce memory. This generator will be fed to the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc09f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    batch_size = 100\n",
    "    batch_size_2 = 400\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    while True:\n",
    "        # vectorize the context words and center word\n",
    "        features = vec.transform(x[j:j+batch_size_2])\n",
    "        labels = vec.transform(y[i:i+batch_size])\n",
    "        \n",
    "        # reshape the context words to have 4 words per datapoint\n",
    "        features = features.toarray().reshape(\n",
    "            int(features.shape[0]/4),4,-1).mean(axis=1)\n",
    "        \n",
    "        \n",
    "        yield features, labels.todense()\n",
    "        \n",
    "        \n",
    "        i += batch_size\n",
    "        j += batch_size_2\n",
    "        if i + batch_size > features.shape[0]:\n",
    "            i = 0\n",
    "            j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4fab541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8492"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-honduras",
   "metadata": {},
   "source": [
    "### create and fit the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce412a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "7266/7266 [==============================] - 231s 32ms/step - loss: 1.7245 - accuracy: 0.3789\n",
      "Epoch 2/6\n",
      "7266/7266 [==============================] - 231s 32ms/step - loss: 1.3783 - accuracy: 0.4099\n",
      "Epoch 3/6\n",
      "7266/7266 [==============================] - 230s 32ms/step - loss: 1.3090 - accuracy: 0.3986\n",
      "Epoch 4/6\n",
      "7266/7266 [==============================] - 231s 32ms/step - loss: 1.2974 - accuracy: 0.3957\n",
      "Epoch 5/6\n",
      "7266/7266 [==============================] - 232s 32ms/step - loss: 1.2831 - accuracy: 0.3918\n",
      "Epoch 6/6\n",
      "7266/7266 [==============================] - 232s 32ms/step - loss: 1.2516 - accuracy: 0.3868\n"
     ]
    }
   ],
   "source": [
    "gen1 = gen()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_dim=len(vec.vocabulary_), activation='relu'))\n",
    "model.add(Dense(len(vec.vocabulary_), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(gen1, steps_per_epoch=int(len(y)/100), verbose=True, epochs=6, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff044a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73acdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the weights of the first layers as the embeddings\n",
    "embeddings = model.layers[0].weights[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e31813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedings.shape: (8492, 80)\n",
      "len(vec.vocabulary_): 8492\n"
     ]
    }
   ],
   "source": [
    "print(f'embedings.shape: {embeddings.shape}')\n",
    "print(f'len(vec.vocabulary_): {len(vec.vocabulary_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-ceramic",
   "metadata": {},
   "source": [
    "### we can test the quality of the embeddings by sampling some words and listing other words with similar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df948b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric='l2').fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "august-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vec.vocabulary_\n",
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "controlled-traveler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiding : dip wound entitled\n",
      "mailbox : permit owing shot\n",
      "opted : flirting soil slab\n",
      "slipped : age shark hack\n",
      "doe : jefferson staircase outta\n",
      "esp : simply draped editor\n",
      "tender : meat dispute seen\n",
      "require : borrow separated tart\n",
      "meant : remark rack immature\n",
      "regarded : humble voucher gah\n",
      "pope : warped giddy cynical\n",
      "did : yes sisterinlaw symbol\n",
      "reminded : kick principal dummy\n",
      "hooked : teacher block commie\n",
      "hottie : ski rolled relief\n",
      "son : however eternity halfway\n",
      "touched : grilled blessing hmmmmm\n",
      "expected : justice monthly deep\n",
      "dimension : coveted gotta scifi\n",
      "arrogant : carried company screwing\n",
      "cellphone : shade distract sydney\n",
      "facet : invented government modeling\n",
      "booty : worldly his dare\n",
      "black : referring line yo\n",
      "patrol : laden essential wildly\n",
      "corner : energy skim flush\n",
      "junior : correctly landing being\n",
      "wondering : ironic spreading tiger\n",
      "lecture : guided glow truth\n",
      "next : milpitas offend series\n"
     ]
    }
   ],
   "source": [
    "# get 30 random words in the vocabulary\n",
    "words = []\n",
    "\n",
    "for i in range(30):\n",
    "    word = random.choice(list(vocab))\n",
    "    \n",
    "    words.append(word)\n",
    "    \n",
    "    idx = vocab[word]\n",
    "        \n",
    "    embedding = embeddings[idx].reshape(1,-1)\n",
    "    \n",
    "    distances, indices = nbrs.kneighbors(embedding)\n",
    "    \n",
    "    # remove the first word since it's always the same word which we're trying to get the neigbhors of\n",
    "    indices = indices[0][1:]\n",
    "    \n",
    "    print(\n",
    "        word,\n",
    "        ':',\n",
    "        *[inv_vocab[w] for w in indices]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-configuration",
   "metadata": {},
   "source": [
    "### based on the above results, the quality of the embeddings does not seem very high\n",
    "### possible improvements include: \n",
    "- using a much larger corpus. this is a very small corpus for training such a model\n",
    "- larger vector embeddings\n",
    "- training the data on more epochs\n",
    "- better preprocessing of the corpus such as autocorrecting misspelled words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-period",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-german",
   "metadata": {},
   "source": [
    "### testing a ready Word2Vec model on the same corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "public-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_as_list = [sentence.split() for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "loaded-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the word2vec model\n",
    "model = Word2Vec(sentences=corpus_as_list, size=80, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "demonstrated-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiding : connected race except\n",
      "mailbox : pant hair throat\n",
      "opted : buck nurturing prop\n",
      "slipped : returned flew hit\n",
      "doe : doesnt meant exactly\n",
      "esp : english sucked charles\n",
      "tender : oakland university quarterly\n",
      "require : extend appear increase\n",
      "meant : rude comfortable impossible\n",
      "regarded : urban canadian sealed\n",
      "pope : envelope spokesman eugene\n",
      "did : shouldnt sux clumsily\n",
      "reminded : crazy noticing mention\n",
      "hooked : hook finger lay\n",
      "hottie : baked agains spoiling\n",
      "son : father neck kaptur\n",
      "touched : dean kerry displayed\n",
      "expected : unfortunately serious lucky\n",
      "dimension : misuse term importantly\n",
      "arrogant : presidential rat carefully\n",
      "cellphone : form simplicity inspiration\n",
      "facet : moral devoid emotion\n",
      "booty : sprinkling barking headset\n",
      "black : chain ice brown\n",
      "patrol : quietly colin removed\n",
      "corner : side area bus\n",
      "junior : grandmother defense empty\n",
      "wondering : exactly kidding yes\n",
      "lecture : september foot chair\n",
      "next : over every sunday\n"
     ]
    }
   ],
   "source": [
    "# testing word2vec on the same words as tested above\n",
    "for word in words:\n",
    "    vector = model.wv[word]  # get numpy vector of a word\n",
    "    sims = model.wv.most_similar(word, topn=10)  # g\n",
    "    \n",
    "    print(\n",
    "        word,\n",
    "        ':',\n",
    "        *[w[0] for w in sims[0:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-antenna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
